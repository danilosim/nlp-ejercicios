{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ftPlyanuak8n",
        "outputId": "45a94d0e-49e7-4f7c-c806-7d5b66779dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ]
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "print(newsgroups_train.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "dcca5de6-dac1-4d68-d284-ce7be2ed9e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "Cantidad de documentos: 11314\n",
            "Tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'Cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'Tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "95111464-e40c-4b57-d154-ede153739a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "93d09f31-4c42-4215-e750-a13c83ecf96a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "59799046-9799-406f-c4be-81c5765de58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "b2bd8485-40c7-4923-c8a9-4ad6b735576e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "747a3923-4b1c-4e2b-921d-4ebf2b271b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ], shape=(11314,))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "04ddf3ca-0741-42d7-8bbb-00bb395f7834"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 4811,  6635,  4253, ...,  1534, 10055,  4750], shape=(11314,))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "926186cf-7d4c-4bd3-927b-ad00bf7f24f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "daf534e5-b2a8-43d4-d05a-9c52b816cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TPM0thDaLk0R",
        "outputId": "bc7fdc3e-d912-4e0c-9d9e-33efc97b46fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  display: none;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  overflow: visible;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".estimator-table summary {\n",
              "    padding: .5rem;\n",
              "    font-family: monospace;\n",
              "    cursor: pointer;\n",
              "}\n",
              "\n",
              ".estimator-table details[open] {\n",
              "    padding-left: 0.1rem;\n",
              "    padding-right: 0.1rem;\n",
              "    padding-bottom: 0.3rem;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table {\n",
              "    margin-left: auto !important;\n",
              "    margin-right: auto !important;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(odd) {\n",
              "    background-color: #fff;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(even) {\n",
              "    background-color: #f6f6f6;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:hover {\n",
              "    background-color: #e0e0e0;\n",
              "}\n",
              "\n",
              ".estimator-table table td {\n",
              "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
              "}\n",
              "\n",
              ".user-set td {\n",
              "    color:rgb(255, 94, 0);\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td.value pre {\n",
              "    color:rgb(255, 94, 0) !important;\n",
              "    background-color: transparent !important;\n",
              "}\n",
              "\n",
              ".default td {\n",
              "    color: black;\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td i,\n",
              ".default td i {\n",
              "    color: black;\n",
              "}\n",
              "\n",
              ".copy-paste-icon {\n",
              "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
              "    background-repeat: no-repeat;\n",
              "    background-size: 14px 14px;\n",
              "    background-position: 0;\n",
              "    display: inline-block;\n",
              "    width: 14px;\n",
              "    height: 14px;\n",
              "    cursor: pointer;\n",
              "}\n",
              "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
              "        <div class=\"estimator-table\">\n",
              "            <details>\n",
              "                <summary>Parameters</summary>\n",
              "                <table class=\"parameters-table\">\n",
              "                  <tbody>\n",
              "                    \n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('alpha',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">alpha&nbsp;</td>\n",
              "            <td class=\"value\">1.0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('force_alpha',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">force_alpha&nbsp;</td>\n",
              "            <td class=\"value\">True</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('fit_prior',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">fit_prior&nbsp;</td>\n",
              "            <td class=\"value\">True</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('class_prior',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">class_prior&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "                  </tbody>\n",
              "                </table>\n",
              "            </details>\n",
              "        </div>\n",
              "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
              "    // Get the parameter prefix from the closest toggleable content\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
              "\n",
              "    const originalStyle = element.style;\n",
              "    const computedStyle = window.getComputedStyle(element);\n",
              "    const originalWidth = computedStyle.width;\n",
              "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
              "\n",
              "    navigator.clipboard.writeText(fullParamName)\n",
              "        .then(() => {\n",
              "            element.style.width = originalWidth;\n",
              "            element.style.color = 'green';\n",
              "            element.innerHTML = \"Copied!\";\n",
              "\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        })\n",
              "        .catch(err => {\n",
              "            console.error('Failed to copy:', err);\n",
              "            element.style.color = 'red';\n",
              "            element.innerHTML = \"Failed!\";\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        });\n",
              "    return false;\n",
              "}\n",
              "\n",
              "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
              "\n",
              "    element.setAttribute('title', fullParamName);\n",
              "});\n",
              "</script></body>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "232ee2ce-e904-466e-be57-babc1f319029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad.\n",
        "\n",
        "**3**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**4**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparación de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documentos seleccionados al azar:\n",
            "[11200  5836  4362  5309  4422]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)  # Para reproducibilidad\n",
        "random_docs = np.random.choice(len(newsgroups_train.data), 5, replace=False)\n",
        "\n",
        "print(\"Documentos seleccionados al azar:\")\n",
        "print(random_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Documento 11200:\n",
            "Categoría: rec.motorcycles\n",
            "Texto (primeros 400 caracteres): Does anyone have a rear wheel for a PD they'd like to part with?\n",
            "\n",
            "Does anyone know where I might find one salvage?\n",
            "\n",
            "As long as I'm getting the GIVI luggage for Brunnhilde and have\n",
            "the room, I thought I'd carry a spare.\n",
            "\n",
            "Ride Free,\n",
            "\n",
            "Bill\n",
            "___________________________________________________________________             \n",
            "johnsw@wsuvm1.csc.wsu.edu  prez=BIMC  KotV KotRR                                \n",
            "D...\n",
            "\n",
            "Los 5 documentos más similares:\n",
            "\n",
            "  1. Índice: 10480, Similaridad: 0.1995, Categoría: sci.med\n",
            "     Texto (primeros 300 caracteres): \n",
            "\n",
            "does anyone know?\n",
            "\n",
            "-- ...\n",
            "\n",
            "  2. Índice: 10966, Similaridad: 0.1772, Categoría: talk.politics.misc\n",
            "     Texto (primeros 300 caracteres): does anyone have Prez. Clinton`s e-mail address.\n",
            "thanks a lot \n",
            " \n",
            "\n",
            "\n",
            "...\n",
            "\n",
            "  3. Índice: 4930, Similaridad: 0.1298, Categoría: rec.motorcycles\n",
            "     Texto (primeros 300 caracteres): This is a periodic posting intended to answer the Frequently Asked\n",
            "Question: What is the DoD? It is posted the first of each month, with\n",
            "an expiration time of over a month. Thus, unless your site's news\n",
            "software is ill-mannered, this posting should always be available.\n",
            "This WitDoDFAQ is crossposted ...\n",
            "\n",
            "  4. Índice: 4964, Similaridad: 0.1220, Categoría: misc.forsale\n",
            "     Texto (primeros 300 caracteres): The subject line says it all -- I'm trying to locate a copy of SPI's\n",
            "board game \"War of the Ring.\"  Anyone have a copy with which they are\n",
            "willing to part?\n",
            "\n",
            "Thanks a million ......\n",
            "\n",
            "  5. Índice: 5273, Similaridad: 0.1159, Categoría: comp.sys.mac.hardware\n",
            "     Texto (primeros 300 caracteres): Does anyone know what hardware is required and where I could find it for\n",
            "sound recording on the  Mac Portable.\n",
            "\n",
            "Thanks...\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nDocumento 11200:\")\n",
        "print(f\"Categoría: {newsgroups_train.target_names[y_train[11200]]}\")\n",
        "print(f\"Texto (primeros 400 caracteres): {newsgroups_train.data[11200][:400]}...\")\n",
        "\n",
        "doc_similarity = cosine_similarity(X_train[11200], X_train)[0]\n",
        "\n",
        "most_similar_indices = np.argsort(doc_similarity)[::-1][1:6]\n",
        "\n",
        "print(f\"\\nLos 5 documentos más similares:\")\n",
        "for j, sim_idx in enumerate(most_similar_indices):\n",
        "    similarity_score = doc_similarity[sim_idx]\n",
        "    category = newsgroups_train.target_names[y_train[sim_idx]]\n",
        "    print(f\"\\n  {j+1}. Índice: {sim_idx}, Similaridad: {similarity_score:.4f}, Categoría: {category}\")\n",
        "    print(f\"     Texto (primeros 300 caracteres): {newsgroups_train.data[sim_idx][:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este primer caso vemos que las categorías casi nunca coinciden, pero si se puede ver similaridad en los textos. Por ejemplo, las palabras \"Does\" y \"Anyone\" se repiten el los dos documentos con más similaridad al de pruebas. Como son documentos cortos, solo tenemos esa información para compararlos y terminan siendo similares a pesar de sus diferencias categóricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Documento 5836:\n",
            "Categoría: talk.religion.misc\n",
            "Texto (primeros 400 caracteres): What are the consequences of the homophobic ranting of the\n",
            "self-righteous?  Well, I just noted this on another group,\n",
            "and thought I'd pass it along.  The context is talk.origins,\n",
            "and a report of yet another \"debate\" that was nothing but an\n",
            "attempt at mindless bullying and factless assertion by a\n",
            "standard-issue Creationist.  The writer reflects that the\n",
            "behavior reported reminds him of some Christi...\n",
            "\n",
            "Los 5 documentos más similares:\n",
            "\n",
            "  1. Índice: 5826, Similaridad: 0.3325, Categoría: soc.religion.christian\n",
            "     Texto (primeros 300 caracteres): A listmember (D Andrew Killie, I think) wrote, in response to the\n",
            "suggestion that genocide may sometimes be the will of God:\n",
            "\n",
            " > Any God who works that way is indescribably evil,\n",
            " > and unworthy of my worship or faith.\n",
            "\n",
            "Nobuya \"Higgy\" Higashiyama replied (as, in substance, did others):\n",
            "\n",
            " > Where is ...\n",
            "\n",
            "  2. Índice: 10836, Similaridad: 0.3325, Categoría: alt.atheism\n",
            "     Texto (primeros 300 caracteres): Archive-name: atheism/faq\n",
            "Alt-atheism-archive-name: faq\n",
            "Last-modified: 5 April 1993\n",
            "Version: 1.1\n",
            "\n",
            "                    Alt.Atheism Frequently-Asked Questions\n",
            "\n",
            "This file contains responses to articles which occur repeatedly in\n",
            "alt.atheism.  Points covered here are ones which are not covered in the\n",
            "\"In...\n",
            "\n",
            "  3. Índice: 913, Similaridad: 0.3289, Categoría: alt.atheism\n",
            "     Texto (primeros 300 caracteres): The recent rise of nostalgia in this group, combined with the\n",
            "  incredible level of utter bullshit, has prompted me to comb\n",
            "  through my archives and pull out some of \"The Best of Alt.Atheism\"\n",
            "  for your reading pleasure.  I'll post a couple of these a day\n",
            "  unless group concensus demands that I sto...\n",
            "\n",
            "  4. Índice: 7464, Similaridad: 0.3110, Categoría: soc.religion.christian\n",
            "     Texto (primeros 300 caracteres): Golgotha the whole process of the fall of man\n",
            "\n",
            "This was precisely my point.  From a theological bent, those who lived\n",
            "immediately after the flood, such as Noah, Ham, his son Cush, and his son\n",
            "Nimrod had a much stronger appreciation of Divine wrath.  They also had a\n",
            "stronger understanding of the True...\n",
            "\n",
            "  5. Índice: 9623, Similaridad: 0.3004, Categoría: talk.politics.mideast\n",
            "     Texto (primeros 300 caracteres): Accounts of Anti-Armenian Human Right Violations in Azerbaijan #012\n",
            "                 Prelude to Current Events in Nagorno-Karabakh\n",
            "\n",
            "        +---------------------------------------------------------+\n",
            "        |                                                         |\n",
            "        |  I saw a naked girl wi...\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nDocumento 5836:\")\n",
        "print(f\"Categoría: {newsgroups_train.target_names[y_train[5836]]}\")\n",
        "print(f\"Texto (primeros 400 caracteres): {newsgroups_train.data[5836][:400]}...\")\n",
        "\n",
        "doc_similarity = cosine_similarity(X_train[5836], X_train)[0]\n",
        "\n",
        "most_similar_indices = np.argsort(doc_similarity)[::-1][1:6]\n",
        "\n",
        "print(f\"\\nLos 5 documentos más similares:\")\n",
        "for j, sim_idx in enumerate(most_similar_indices):\n",
        "    similarity_score = doc_similarity[sim_idx]\n",
        "    category = newsgroups_train.target_names[y_train[sim_idx]]\n",
        "    print(f\"\\n  {j+1}. Índice: {sim_idx}, Similaridad: {similarity_score:.4f}, Categoría: {category}\")\n",
        "    print(f\"     Texto (primeros 300 caracteres): {newsgroups_train.data[sim_idx][:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso todas las categorías están relacionadas por más que no son exactamente las mismas. La categoría \"religion misc\" probablemente comparte muchas palabras en común como \"god\" con las categorías \"religion atheism\", \"religion christian\" y \"politics mideast\" (ya que la política en el medio oriente generalmente involucra temas religiosos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Documento 4362:\n",
            "Categoría: soc.religion.christian\n",
            "Texto (primeros 400 caracteres): A \"new Christian\" wrote that he was new to the faith and \n",
            "learning about it \"by reading the Bible, of course\". I am not\n",
            "at all sure this is the best path to follow.\n",
            "\tWhile the Bible is, for Christians, the word of God, the \n",
            "revelation of God is Jesus Christ and the chief legacy of this\n",
            "revalation is the Church. I am not recommending any one\n",
            "denommination, but I do recommend finding a comfortable c...\n",
            "\n",
            "Los 5 documentos más similares:\n",
            "\n",
            "  1. Índice: 2772, Similaridad: 0.4560, Categoría: soc.religion.christian\n",
            "     Texto (primeros 300 caracteres): \n",
            "\n",
            "The problem you see here is that some Christians claim things about\n",
            "the Bible which they don't actually believe or practice. I've known\n",
            "all sorts of Christians, ranging from the trendiest of liberals to\n",
            "the fire-breathing fundamentalists, and although many on the \n",
            "conservative side of the Christia...\n",
            "\n",
            "  2. Índice: 9914, Similaridad: 0.4464, Categoría: soc.religion.christian\n",
            "     Texto (primeros 300 caracteres): Hi,\n",
            "\n",
            "I am new to this newsgroup, and also fairly new to christianity. I was\n",
            "raised as a Unitarian and have spent the better part of my life as an\n",
            "agnostic, but recently I have developed the firm conviction that the\n",
            "Christian message is correct and I have accepted Jesus into my life. I am\n",
            "happy, but ...\n",
            "\n",
            "  3. Índice: 10550, Similaridad: 0.4357, Categoría: talk.religion.misc\n",
            "     Texto (primeros 300 caracteres): \n",
            "#Rick Anderson replied to my letter with...\n",
            "#\n",
            "#ra> In article <C5ELp2.L0C@acsu.buffalo.edu>,\n",
            "#ra>\n",
            "\n",
            "(...)\n",
            "\n",
            "# Just briefly, on something that you mentioned in passing. You refer to\n",
            "# differing interpretations of \"create,\" and say that many Christians may\n",
            "# not agree. So what? That is really irrelevan...\n",
            "\n",
            "  4. Índice: 11153, Similaridad: 0.4344, Categoría: talk.religion.misc\n",
            "     Texto (primeros 300 caracteres): \n",
            "#Rick Anderson replied to my letter with...\n",
            "#\n",
            "#ra> In article <C5ELp2.L0C@acsu.buffalo.edu>,\n",
            "#ra>\n",
            "\n",
            "(...)\n",
            "\n",
            "# Just briefly, on something that you mentioned in passing. You refer to\n",
            "# differing interpretations of \"create,\" and say that many Christians may\n",
            "# not agree. So what? That is really irrelevan...\n",
            "\n",
            "  5. Índice: 913, Similaridad: 0.4333, Categoría: alt.atheism\n",
            "     Texto (primeros 300 caracteres): The recent rise of nostalgia in this group, combined with the\n",
            "  incredible level of utter bullshit, has prompted me to comb\n",
            "  through my archives and pull out some of \"The Best of Alt.Atheism\"\n",
            "  for your reading pleasure.  I'll post a couple of these a day\n",
            "  unless group concensus demands that I sto...\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nDocumento 4362:\")\n",
        "print(f\"Categoría: {newsgroups_train.target_names[y_train[4362]]}\")\n",
        "print(f\"Texto (primeros 400 caracteres): {newsgroups_train.data[4362][:400]}...\")\n",
        "\n",
        "doc_similarity = cosine_similarity(X_train[4362], X_train)[0]\n",
        "\n",
        "most_similar_indices = np.argsort(doc_similarity)[::-1][1:6]\n",
        "\n",
        "print(f\"\\nLos 5 documentos más similares:\")\n",
        "for j, sim_idx in enumerate(most_similar_indices):\n",
        "    similarity_score = doc_similarity[sim_idx]\n",
        "    category = newsgroups_train.target_names[y_train[sim_idx]]\n",
        "    print(f\"\\n  {j+1}. Índice: {sim_idx}, Similaridad: {similarity_score:.4f}, Categoría: {category}\")\n",
        "    print(f\"     Texto (primeros 300 caracteres): {newsgroups_train.data[sim_idx][:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso sucede algo similar a lo anterior, resaltando palabras como \"christian\" que aparecen en varios documentos relacionados con la religión, especialmente en los contextos de \"religion christian\" y \"religion misc\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Documento 5309:\n",
            "Categoría: talk.religion.misc\n",
            "Texto (primeros 400 caracteres): \n",
            "Glad to hear this, just a note, Osiris, Mithras and many other\n",
            "cult gods resurrected as well, so there's a good chance for all of\n",
            "us to maybe end up in a virtual reality simulator, and live forever,\n",
            "hurrah!\n",
            "\n",
            "Sorry, this was a joke, some sort of one anyway. I'm the first\n",
            "that connected Osiris with a virtual reality personality database.\n",
            "Time to write a book.\n",
            "\n",
            "\n",
            "Cheers,\n",
            "Kent...\n",
            "\n",
            "Los 5 documentos más similares:\n",
            "\n",
            "  1. Índice: 10480, Similaridad: 0.1995, Categoría: sci.med\n",
            "     Texto (primeros 300 caracteres): \n",
            "\n",
            "does anyone know?\n",
            "\n",
            "-- ...\n",
            "\n",
            "  2. Índice: 10966, Similaridad: 0.1772, Categoría: talk.politics.misc\n",
            "     Texto (primeros 300 caracteres): does anyone have Prez. Clinton`s e-mail address.\n",
            "thanks a lot \n",
            " \n",
            "\n",
            "\n",
            "...\n",
            "\n",
            "  3. Índice: 4930, Similaridad: 0.1298, Categoría: rec.motorcycles\n",
            "     Texto (primeros 300 caracteres): This is a periodic posting intended to answer the Frequently Asked\n",
            "Question: What is the DoD? It is posted the first of each month, with\n",
            "an expiration time of over a month. Thus, unless your site's news\n",
            "software is ill-mannered, this posting should always be available.\n",
            "This WitDoDFAQ is crossposted ...\n",
            "\n",
            "  4. Índice: 4964, Similaridad: 0.1220, Categoría: misc.forsale\n",
            "     Texto (primeros 300 caracteres): The subject line says it all -- I'm trying to locate a copy of SPI's\n",
            "board game \"War of the Ring.\"  Anyone have a copy with which they are\n",
            "willing to part?\n",
            "\n",
            "Thanks a million ......\n",
            "\n",
            "  5. Índice: 5273, Similaridad: 0.1159, Categoría: comp.sys.mac.hardware\n",
            "     Texto (primeros 300 caracteres): Does anyone know what hardware is required and where I could find it for\n",
            "sound recording on the  Mac Portable.\n",
            "\n",
            "Thanks...\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nDocumento 5309:\")\n",
        "print(f\"Categoría: {newsgroups_train.target_names[y_train[5309]]}\")\n",
        "print(f\"Texto (primeros 400 caracteres): {newsgroups_train.data[5309][:400]}...\")\n",
        "\n",
        "doc_similarity = cosine_similarity(X_train[11200], X_train)[0]\n",
        "\n",
        "most_similar_indices = np.argsort(doc_similarity)[::-1][1:6]\n",
        "\n",
        "print(f\"\\nLos 5 documentos más similares:\")\n",
        "for j, sim_idx in enumerate(most_similar_indices):\n",
        "    similarity_score = doc_similarity[sim_idx]\n",
        "    category = newsgroups_train.target_names[y_train[sim_idx]]\n",
        "    print(f\"\\n  {j+1}. Índice: {sim_idx}, Similaridad: {similarity_score:.4f}, Categoría: {category}\")\n",
        "    print(f\"     Texto (primeros 300 caracteres): {newsgroups_train.data[sim_idx][:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso podemos ver casos con valores de similaridad muy bajos, probablemente porque el documento a comparar es muy diferente en contenido a los demás documentos del conjunto y no comparte demasiadas palabras clave."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Documento 4422:\n",
            "Categoría: talk.politics.guns\n",
            "Texto (primeros 400 caracteres): NUT CASE PANICS!!!!JUMPS THE GUN ON THE NET BEFORE GETTING FACTS STRAIGHT!!!!\n",
            "...\n",
            "\n",
            "Los 5 documentos más similares:\n",
            "\n",
            "  1. Índice: 10846, Similaridad: 0.3014, Categoría: talk.politics.guns\n",
            "     Texto (primeros 300 caracteres): NUT CASE PANICS!!!!REALIZES HE'S MADE A COMPLETE FOOL OF HIMSELF IN FRONT OF\n",
            "THOUSANDS OF NETTERS!!!!BACKS AWAY FROM EARLIER RASH STATEMENTS!!!!GOD HAVE\n",
            "MERCY ON HIM!!!!\n",
            "...\n",
            "\n",
            "  2. Índice: 6704, Similaridad: 0.1589, Categoría: sci.space\n",
            "     Texto (primeros 300 caracteres): Okay, lets get the record straight on the Livermore gas gun.  \n",
            "The project manager is Dr. John Hunter, and he works for the\n",
            "Laser group at Livermore.  What, you may ask, does gas guns\n",
            "have to do with lasers? Nothing, really, but the gun is physically\n",
            "located across the road from the Free Electron La...\n",
            "\n",
            "  3. Índice: 11036, Similaridad: 0.1429, Categoría: talk.politics.guns\n",
            "     Texto (primeros 300 caracteres): \n",
            "\tAt the risk of starting the 'my gun is better than yours' flame\n",
            "war, I must disagree.\n",
            "\t\n",
            "\tThere is no secret in handling a Glock.  In fact, it is often\n",
            "chosen (besides its other merits) because it shoots like a revolver does\n",
            "basically.  It can limit the training time (read budget $$$) due to the\n",
            "fa...\n",
            "\n",
            "  4. Índice: 10636, Similaridad: 0.1429, Categoría: talk.politics.guns\n",
            "     Texto (primeros 300 caracteres): I have been convinced of the right of AMericans to an effective \n",
            "self-defense, but something strikes me as odd among the\n",
            "pro-RKBA arguments presented here.\n",
            "\n",
            "The numbers comparing hundreds of thousands (indeed, even a\n",
            "million) of instances of law abiding citizens deterring\n",
            "criminal activity, seem val...\n",
            "\n",
            "  5. Índice: 10737, Similaridad: 0.1358, Categoría: rec.autos\n",
            "     Texto (primeros 300 caracteres): \n",
            "  I would suggest you take the car to the nearest Chevron dealer, with\n",
            "your own oil and filter.  Ask for an oil change.  It will cost less\n",
            "than $10.  Watch him/her do it.  Just from watching someone do a job,\n",
            "you will be able to learn and remember the sequence, and do it right\n",
            "when you do it yourse...\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nDocumento 4422:\")\n",
        "print(f\"Categoría: {newsgroups_train.target_names[y_train[4422]]}\")\n",
        "print(f\"Texto (primeros 400 caracteres): {newsgroups_train.data[4422][:400]}...\")\n",
        "\n",
        "doc_similarity = cosine_similarity(X_train[4422], X_train)[0]\n",
        "\n",
        "most_similar_indices = np.argsort(doc_similarity)[::-1][1:6]\n",
        "\n",
        "print(f\"\\nLos 5 documentos más similares:\")\n",
        "for j, sim_idx in enumerate(most_similar_indices):\n",
        "    similarity_score = doc_similarity[sim_idx]\n",
        "    category = newsgroups_train.target_names[y_train[sim_idx]]\n",
        "    print(f\"\\n  {j+1}. Índice: {sim_idx}, Similaridad: {similarity_score:.4f}, Categoría: {category}\")\n",
        "    print(f\"     Texto (primeros 300 caracteres): {newsgroups_train.data[sim_idx][:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso de comparación final, podemos ver que la categoría original \"Politics Guns\" tiene una palabra muy particular que seguramente aparezca en la mayoría de los casos, \"guns\". Es por eso que la mayoría de las similitudes encontradas están relacionadas con esta palabra clave, lo que indica que los documentos que comparten esta palabra tienden a ser más similares entre sí."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clasificación zero-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesados 1000/7532 documentos\n",
            "Procesados 2000/7532 documentos\n",
            "Procesados 3000/7532 documentos\n",
            "Procesados 4000/7532 documentos\n",
            "Procesados 5000/7532 documentos\n",
            "Procesados 6000/7532 documentos\n",
            "Procesados 7000/7532 documentos\n"
          ]
        }
      ],
      "source": [
        "# Modelo de clasificación por prototipos (zero-shot)\n",
        "# Clasificamos cada documento de test comparando con todos los de train\n",
        "# y asignando la clase del documento más similar\n",
        "\n",
        "def prototype_classify(X_train, y_train, X_test):\n",
        "    predictions = []\n",
        "    \n",
        "    for i in range(X_test.shape[0]):\n",
        "        # Calcular similaridad coseno entre el documento de test y todos los de train\n",
        "        similarities = cosine_similarity(X_test[i], X_train)[0]\n",
        "        \n",
        "        # Encontrar el índice del documento más similar\n",
        "        most_similar_idx = np.argmax(similarities)\n",
        "        \n",
        "        # Asignar la clase del documento más similar\n",
        "        predicted_class = y_train[most_similar_idx]\n",
        "        predictions.append(predicted_class)\n",
        "        \n",
        "        # Mostrar progreso cada 1000 documentos\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            print(f\"Procesados {i + 1}/{X_test.shape[0]} documentos\")\n",
        "    \n",
        "    return np.array(predictions)\n",
        "\n",
        "# Ejecutar la clasificación por prototipos\n",
        "y_pred_prototype = prototype_classify(X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score macro del modelo de prototipos: 0.5050\n",
            "F1-score macro del modelo Naive Bayes: 0.5854\n",
            "\n",
            "Diferencia: 0.0804\n"
          ]
        }
      ],
      "source": [
        "f1_prototype = f1_score(y_test, y_pred_prototype, average='macro')\n",
        "print(f\"F1-score macro del modelo de prototipos: {f1_prototype:.4f}\")\n",
        "\n",
        "f1_nb = f1_score(y_test, y_pred, average='macro')\n",
        "print(f\"F1-score macro del modelo Naive Bayes: {f1_nb:.4f}\")\n",
        "\n",
        "print(f\"\\nDiferencia: {f1_nb - f1_prototype:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes mejorado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Configuración 1: {'max_features': 10000, 'min_df': 2, 'max_df': 0.95, 'ngram_range': (1, 1)}\n",
            "  MultinomialNB: F1-score = 0.6156\n",
            "  ComplementNB: F1-score = 0.6668\n",
            "\n",
            "Configuración 2: {'max_features': 15000, 'min_df': 2, 'max_df': 0.95, 'ngram_range': (1, 2)}\n",
            "  MultinomialNB: F1-score = 0.5853\n",
            "  ComplementNB: F1-score = 0.6520\n",
            "\n",
            "Configuración 3: {'max_features': 20000, 'min_df': 3, 'max_df': 0.9, 'ngram_range': (1, 1)}\n",
            "  MultinomialNB: F1-score = 0.6083\n",
            "  ComplementNB: F1-score = 0.6862\n",
            "\n",
            "Configuración 4: {'max_features': None, 'min_df': 5, 'max_df': 0.8, 'ngram_range': (1, 2)}\n",
            "  MultinomialNB: F1-score = 0.5813\n",
            "  ComplementNB: F1-score = 0.6840\n",
            "\n",
            "==================================================\n",
            "MEJOR RESULTADO:\n",
            "Modelo: ComplementNB\n",
            "F1-score: 0.6862\n",
            "Configuración del vectorizador: {'max_features': 20000, 'min_df': 3, 'max_df': 0.9, 'ngram_range': (1, 1)}\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "vectorizer_configs = [\n",
        "    {'max_features': 10000, 'min_df': 2, 'max_df': 0.95, 'ngram_range': (1, 1)},\n",
        "    {'max_features': 15000, 'min_df': 2, 'max_df': 0.95, 'ngram_range': (1, 2)},\n",
        "    {'max_features': 20000, 'min_df': 3, 'max_df': 0.9, 'ngram_range': (1, 1)},\n",
        "    {'max_features': None, 'min_df': 5, 'max_df': 0.8, 'ngram_range': (1, 2)}\n",
        "]\n",
        "\n",
        "models = {\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'ComplementNB': ComplementNB()\n",
        "}\n",
        "\n",
        "best_f1 = 0\n",
        "best_config = None\n",
        "best_model_name = None\n",
        "best_vectorizer = None\n",
        "best_model = None\n",
        "\n",
        "for i, config in enumerate(vectorizer_configs):\n",
        "    print(f\"\\nConfiguración {i+1}: {config}\")\n",
        "    \n",
        "    # Crear nuevo vectorizador con la configuración actual\n",
        "    vectorizer = TfidfVectorizer(**config)\n",
        "    \n",
        "    # Vectorizar los datos\n",
        "    X_train_config = vectorizer.fit_transform(newsgroups_train.data)\n",
        "    X_test_config = vectorizer.transform(newsgroups_test.data)\n",
        "    \n",
        "    # Probar ambos modelos\n",
        "    for model_name, model in models.items():\n",
        "        # Entrenar el modelo\n",
        "        model.fit(X_train_config, y_train)\n",
        "        \n",
        "        # Predecir en test\n",
        "        y_pred_config = model.predict(X_test_config)\n",
        "        \n",
        "        # Calcular F1-score\n",
        "        f1_config = f1_score(y_test, y_pred_config, average='macro')\n",
        "        \n",
        "        print(f\"  {model_name}: F1-score = {f1_config:.4f}\")\n",
        "        \n",
        "        # Guardar si es el mejor resultado\n",
        "        if f1_config > best_f1:\n",
        "            best_f1 = f1_config\n",
        "            best_config = config\n",
        "            best_model_name = model_name\n",
        "            best_vectorizer = vectorizer\n",
        "            best_model = model\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"MEJOR RESULTADO:\")\n",
        "print(f\"Modelo: {best_model_name}\")\n",
        "print(f\"F1-score: {best_f1:.4f}\")\n",
        "print(f\"Configuración del vectorizador: {best_config}\")\n",
        "print(f\"{'='*50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matriz término-documento y similaridad entre palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz documento-término original: (11314, 101631)\n",
            "Matriz término-documento transpuesta: (101631, 11314)\n",
            "\n",
            "Palabras seleccionadas para análisis: ['computer', 'car', 'god', 'gun', 'space']\n",
            "'computer' encontrada en índice: 28940\n",
            "'car' encontrada en índice: 25775\n",
            "'god' encontrada en índice: 43842\n",
            "'gun' encontrada en índice: 44820\n",
            "'space' encontrada en índice: 84097\n",
            "\n",
            "============================================================\n",
            "\n",
            "Análisis de similaridad para 'computer':\n",
            "Las 5 palabras más similares a 'computer':\n",
            "  1. 'decwriter' - Similaridad: 0.1563\n",
            "  2. 'harkens' - Similaridad: 0.1522\n",
            "  3. 'deluged' - Similaridad: 0.1522\n",
            "  4. 'shopper' - Similaridad: 0.1443\n",
            "  5. 'the' - Similaridad: 0.1361\n",
            "\n",
            "Análisis de similaridad para 'car':\n",
            "Las 5 palabras más similares a 'car':\n",
            "  1. 'cars' - Similaridad: 0.1797\n",
            "  2. 'criterium' - Similaridad: 0.1770\n",
            "  3. 'civic' - Similaridad: 0.1748\n",
            "  4. 'owner' - Similaridad: 0.1689\n",
            "  5. 'dealer' - Similaridad: 0.1681\n",
            "\n",
            "Análisis de similaridad para 'god':\n",
            "Las 5 palabras más similares a 'god':\n",
            "  1. 'jesus' - Similaridad: 0.2688\n",
            "  2. 'bible' - Similaridad: 0.2616\n",
            "  3. 'that' - Similaridad: 0.2560\n",
            "  4. 'existence' - Similaridad: 0.2548\n",
            "  5. 'christ' - Similaridad: 0.2511\n",
            "\n",
            "Análisis de similaridad para 'gun':\n",
            "Las 5 palabras más similares a 'gun':\n",
            "  1. 'guns' - Similaridad: 0.3582\n",
            "  2. 'crime' - Similaridad: 0.2441\n",
            "  3. 'handgun' - Similaridad: 0.2391\n",
            "  4. 'homicides' - Similaridad: 0.2331\n",
            "  5. 'firearms' - Similaridad: 0.2328\n",
            "\n",
            "Análisis de similaridad para 'space':\n",
            "Las 5 palabras más similares a 'space':\n",
            "  1. 'nasa' - Similaridad: 0.3304\n",
            "  2. 'seds' - Similaridad: 0.2966\n",
            "  3. 'shuttle' - Similaridad: 0.2928\n",
            "  4. 'enfant' - Similaridad: 0.2803\n",
            "  5. 'seti' - Similaridad: 0.2465\n"
          ]
        }
      ],
      "source": [
        "X_term_doc = X_train.T\n",
        "\n",
        "print(f\"Matriz documento-término original: {X_train.shape}\")\n",
        "print(f\"Matriz término-documento transpuesta: {X_term_doc.shape}\")\n",
        "\n",
        "palabras_seleccionadas = ['computer', 'car', 'god', 'gun', 'space']\n",
        "\n",
        "print(f\"\\nPalabras seleccionadas para análisis: {palabras_seleccionadas}\")\n",
        "\n",
        "word_indices = {}\n",
        "for palabra in palabras_seleccionadas:\n",
        "    if palabra in tfidfvect.vocabulary_:\n",
        "        word_indices[palabra] = tfidfvect.vocabulary_[palabra]\n",
        "        print(f\"'{palabra}' encontrada en índice: {word_indices[palabra]}\")\n",
        "    else:\n",
        "        print(f\"'{palabra}' NO encontrada en el vocabulario\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "for palabra, idx in word_indices.items():\n",
        "    print(f\"\\nAnálisis de similaridad para '{palabra}':\")\n",
        "    \n",
        "    word_similarities = cosine_similarity(X_term_doc[idx], X_term_doc)[0]\n",
        "\n",
        "    # Obtener los 5 más similares (excluyendo la palabra misma)\n",
        "    most_similar_word_indices = np.argsort(word_similarities)[::-1][1:6]\n",
        "    \n",
        "    print(f\"Las 5 palabras más similares a '{palabra}':\")\n",
        "    for i, similar_idx in enumerate(most_similar_word_indices):\n",
        "        similarity_score = word_similarities[similar_idx]\n",
        "        similar_word = idx2word[similar_idx]\n",
        "        print(f\"  {i+1}. '{similar_word}' - Similaridad: {similarity_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analizando la similaridad de las palabras elegidas, se puede observar que en la mayoría de los casos las palabras están relacionadas y pueden considerarse que son inherentes al mismo contexto temático. Esto sugiere que el modelo ha capturado adecuadamente las relaciones semánticas entre los términos, lo cual es un indicativo positivo de su desempeño en tareas de clasificación de texto."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp-ejercicios",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
