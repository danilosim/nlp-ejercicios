{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-KdlJXydCkF",
        "outputId": "199c0427-c637-4e3b-a566-867358b93dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset noticias en inglés del archivo news.csv, combinando los campos title y text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVVELjSndCkF",
        "outputId": "85df0410-4088-470a-966b-d386bb9da2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (21417, 4)\n",
            "Columns: ['title', 'text', 'subject', 'date']\n",
            "Subjects: ['politicsNews' 'worldnews']\n",
            "Total text length before cleaning: 91842 characters\n"
          ]
        }
      ],
      "source": [
        "# Load news dataset\n",
        "news_df = pd.read_csv('news.csv')\n",
        "\n",
        "print(f\"Dataset shape: {news_df.shape}\")\n",
        "print(f\"Columns: {news_df.columns.tolist()}\")\n",
        "print(f\"Subjects: {news_df['subject'].unique()}\")\n",
        "\n",
        "# Combine title and text columns\n",
        "news_df['combined_text'] = news_df['title'] + '. ' + news_df['text']\n",
        "\n",
        "# Create the article_text by concatenating all news articles\n",
        "article_text = ' '.join(news_df[:35]['combined_text'].astype(str))\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()\n",
        "\n",
        "print(f\"Total text length before cleaning: {len(article_text)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8cd26682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe2ff0e-7221-45ac-8dc1-f05864466c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text length: 91094 characters\n",
            "Sample: as u.s. budget fight looms, republicans flip their fiscal script. washington reuters - the head of a conservative republican faction in the u.s. congress, who voted this month for a huge expansion of ...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Limpiar texto\n",
        "def clean_text(text):\n",
        "    cleaned = re.sub(r'[^\\w\\s.,!?;:\\-\\'áéíóúñçàèìòùâêîôûäëïöü]', ' ', text, flags=re.UNICODE)\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "    return cleaned\n",
        "\n",
        "article_text = clean_text(article_text)\n",
        "print(f\"Cleaned text length: {len(article_text)} characters\")\n",
        "print(f\"Sample: {article_text[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WBE0sSYuB-E6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8f5429b5-7706-4bc1-f881-27965b64a5bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'as u.s. budget fight looms, republicans flip their fiscal script. washington reuters - the head of a conservative republican faction in the u.s. congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a fiscal conservative on sunday and urged budget restraint in 2018. in keeping with a sharp pivot under way among republicans, u.s. representative mark meadows, speaking on cbs face the nation, drew a hard line on federal spending, which lawmakers are bracing to do battle over in january. when they return from the holidays on wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the november congressional election campaigns approach in which republicans will seek to keep control of congress. president donald trump and his republicans want a big budget increase in military spending, while democrats also want proportional increases for non-defens'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# en article text se encuentra el texto completo\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VwTK6xgLJd8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8c0383-8e3d-41a1-be02-8d2231655a72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PwGVSKOiJ5bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9a165b-9c0a-4c5d-f251-361abf6b3485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 7, 4, 27, 31, 7, 31, 4, 11, 27]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tokenized_text[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaebc7f0"
      },
      "source": [
        "## Comparando diferentes arquitecturas RNN\n",
        "\n",
        "Según la consigna, exploraremos SimpleRNN, LSTM y GRU para implementar el modelo de lenguaje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "cd791c74",
        "outputId": "b7195c2f-5ace-4991-eff0-78ddeb133f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Creando modelo SimpleRNN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m49,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)       │         \u001b[38;5;34m8,844\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,844</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,844\u001b[0m (225.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,844</span> (225.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,844\u001b[0m (225.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,844</span> (225.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Creando modelo LSTM ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m196,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)       │         \u001b[38;5;34m8,844\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,844</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m204,844\u001b[0m (800.17 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">204,844</span> (800.17 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m204,844\u001b[0m (800.17 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">204,844</span> (800.17 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Creando modelo GRU ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m147,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)       │         \u001b[38;5;34m8,844\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,844</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m156,444\u001b[0m (611.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,444</span> (611.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m156,444\u001b[0m (611.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,444</span> (611.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras.layers import LSTM, GRU, Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "def create_model(rnn_type='SimpleRNN', units=200, vocab_size=len(chars_vocab)):\n",
        "    \"\"\"\n",
        "    Crear modelo RNN con diferentes arquitecturas\n",
        "\n",
        "    Args:\n",
        "        rnn_type: 'SimpleRNN', 'LSTM', or 'GRU'\n",
        "        units: number of RNN units\n",
        "        vocab_size: vocabulary size\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(TimeDistributed(CategoryEncoding(num_tokens=len(chars_vocab), output_mode=\"one_hot\"),\n",
        "                             input_shape=(None, 1)))\n",
        "\n",
        "    if rnn_type == 'SimpleRNN':\n",
        "        model.add(SimpleRNN(units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "    elif rnn_type == 'LSTM':\n",
        "        model.add(LSTM(units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "    elif rnn_type == 'GRU':\n",
        "        model.add(GRU(units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "    else:\n",
        "        raise ValueError(\"rnn_type tiene que ser 'SimpleRNN', 'LSTM' o 'GRU'\")\n",
        "\n",
        "    model.add(Dense(len(chars_vocab), activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear modelos\n",
        "models = {}\n",
        "for rnn_type in ['SimpleRNN', 'LSTM', 'GRU']:\n",
        "    print(f\"\\n=== Creando modelo {rnn_type} ===\")\n",
        "    models[rnn_type] = create_model(rnn_type, units=200, vocab_size=len(chars_vocab))\n",
        "    models[rnn_type].summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C3hcIf0rdCkH"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c72151fb",
        "outputId": "8c34ce9f-c7d6-43f0-8025-ab56ce9a7e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - loss: 2.9694\n",
            " mean perplexity: 12.690791130065918 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 675ms/step - loss: 2.9688\n",
            "Epoch 2/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - loss: 2.4266\n",
            " mean perplexity: 11.181818008422852 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 646ms/step - loss: 2.4265\n",
            "Epoch 3/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640ms/step - loss: 2.2630\n",
            " mean perplexity: 10.363110542297363 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 651ms/step - loss: 2.2629\n",
            "Epoch 4/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - loss: 2.1482\n",
            " mean perplexity: 9.822965621948242 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 653ms/step - loss: 2.1482\n",
            "Epoch 5/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - loss: 2.0620\n",
            " mean perplexity: 9.45362663269043 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 653ms/step - loss: 2.0620\n",
            "Epoch 6/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - loss: 1.9929\n",
            " mean perplexity: 9.124748229980469 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 656ms/step - loss: 1.9929\n",
            "Epoch 7/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - loss: 1.9364\n",
            " mean perplexity: 9.262410163879395 \n",
            "\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 654ms/step - loss: 1.9364\n",
            "Epoch 8/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - loss: 1.8853\n",
            " mean perplexity: 8.97881031036377 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 654ms/step - loss: 1.8853\n",
            "Epoch 9/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - loss: 1.8365\n",
            " mean perplexity: 9.04428482055664 \n",
            "\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 649ms/step - loss: 1.8364\n",
            "Epoch 10/10\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633ms/step - loss: 1.7918\n",
            " mean perplexity: 8.933402061462402 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 642ms/step - loss: 1.7918\n"
          ]
        }
      ],
      "source": [
        "selected_model = 'LSTM'\n",
        "\n",
        "print(f\"Training {selected_model} model...\")\n",
        "model = models[selected_model]\n",
        "\n",
        "# Entrenar el modelo\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=10,\n",
        "                callbacks=[PplCallback(tokenized_sentences_val, history_ppl)],\n",
        "                batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K30JHB3Dv-mx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "42a8b0bd-445d-46e9-e7a4-fe369285a835"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89792d3c-3495-45b6-b4a7-5cb280888622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the congress and the past of the past of t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "input_text='the congress'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generación de secuencias\n",
        "\n",
        "Implementaremos las estrategias solicitadas:\n",
        "1. **Greedy search**: Selecciona siempre el token más probable\n",
        "2. **Beam search determinístico**: Mantiene los k mejores candidatos\n",
        "3. **Beam search estocástico**: Muestreo aleatorio con temperatura"
      ],
      "metadata": {
        "id": "lFLBmDeDl8D0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [],
      "source": [
        "def generate_seq_greedy(model, seed_text, max_length, n_chars):\n",
        "    \"\"\"\n",
        "    Greedy search: always select the most probable next character\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "    for _ in range(n_chars):\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower()]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "        # Greedy: select most probable character\n",
        "        y_hat = np.argmax(model.predict(encoded, verbose=0)[0, -1, :])\n",
        "        output_text += idx2char[y_hat]\n",
        "\n",
        "    return output_text\n",
        "\n",
        "def generate_seq_stochastic(model, seed_text, max_length, n_chars, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Stochastic sampling with temperature\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "    for _ in range(n_chars):\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower()]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "        # Get probabilities and apply temperature\n",
        "        probs = model.predict(encoded, verbose=0)[0, -1, :]\n",
        "        probs = np.exp(np.log(probs + 1e-10) / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "\n",
        "        # Sample from the distribution\n",
        "        y_hat = np.random.choice(len(probs), p=probs)\n",
        "        output_text += idx2char[y_hat]\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d4d75aa",
        "outputId": "a301fac1-ad19-4a11-e1f0-3ecae7c8e3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GREEDY SEARCH ===\n",
            "the president donald the past of the past of the past of the past of the past of the past of the past of the past\n",
            "\n",
            "=== STOCHASTIC SAMPLING (Temperature = 0.5) ===\n",
            "the president the law. the fidud the said. the that mo the companies in the republican could spection of state co\n",
            "\n",
            "=== STOCHASTIC SAMPLING (Temperature = 1.0) ===\n",
            "the president of sax al resion of to states need be ponitillive, reoodut, we bald aid law u.s.ly lownel  lof into\n",
            "\n",
            "=== STOCHASTIC SAMPLING (Temperature = 1.5) ===\n",
            "the president on clis!ing precaion ofll rat that it the89ly kovermmed, aby vith ledvoven sunke. fabe !hef mair in\n"
          ]
        }
      ],
      "source": [
        "# Test different generation strategies\n",
        "seed_text = \"the president\"\n",
        "n_chars = 100\n",
        "\n",
        "print(\"=== GREEDY SEARCH ===\")\n",
        "greedy_result = generate_seq_greedy(model, seed_text, max_context_size, n_chars)\n",
        "print(greedy_result)\n",
        "\n",
        "print(\"\\n=== STOCHASTIC SAMPLING (Temperature = 0.5) ===\")\n",
        "stochastic_low = generate_seq_stochastic(model, seed_text, max_context_size, n_chars, temperature=0.5)\n",
        "print(stochastic_low)\n",
        "\n",
        "print(\"\\n=== STOCHASTIC SAMPLING (Temperature = 1.0) ===\")\n",
        "stochastic_mid = generate_seq_stochastic(model, seed_text, max_context_size, n_chars, temperature=1.0)\n",
        "print(stochastic_mid)\n",
        "\n",
        "print(\"\\n=== STOCHASTIC SAMPLING (Temperature = 1.5) ===\")\n",
        "stochastic_high = generate_seq_stochastic(model, seed_text, max_context_size, n_chars, temperature=1.5)\n",
        "print(stochastic_high)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": [
        "###  Beam search determinístico y estocástico\n",
        "\n",
        "Implementamos beam search con ambas variantes según la consigna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7bf730",
        "outputId": "dcde5f85-620d-41f3-d312-a9d35accef6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BEAM SEARCH DETERMINÍSTICO ===\n",
            "Candidate 1: the president donald trump said that the u.s. president donald \n",
            "Candidate 2: the president donald trump said that the u.s. president of the \n",
            "Candidate 3: the president donald trump said that the u.s. president that th\n",
            "\n",
            "=== BEAM SEARCH ESTOCÁSTICO (Temperature = 0.8) ===\n",
            "Candidate 1: the president demections by the past of the court of comment in\n",
            "Candidate 2: the president demections by the past of the court of comment th\n",
            "Candidate 3: the president demections by the past of the court of comment in\n",
            "\n",
            "=== BEAM SEARCH ESTOCÁSTICO (Temperature = 1.2) ===\n",
            "Candidate 1: the president donald the u.s. the count the passial of with for\n",
            "Candidate 2: the president donald the u.s. the count the passial of with mir\n",
            "Candidate 3: the president donald the u.s. the count the passial of with ken\n"
          ]
        }
      ],
      "source": [
        "# Test beam search strategies\n",
        "seed_text = \"the president\"\n",
        "\n",
        "print(\"=== BEAM SEARCH DETERMINÍSTICO ===\")\n",
        "beam_det = beam_search(model, num_beams=5, num_words=50, input=seed_text, mode='det')\n",
        "for i, result in enumerate(beam_det[:3]):  # Show top 3 results\n",
        "    print(f\"Candidate {i+1}: {decode(result)}\")\n",
        "\n",
        "print(\"\\n=== BEAM SEARCH ESTOCÁSTICO (Temperature = 0.8) ===\")\n",
        "beam_sto = beam_search(model, num_beams=5, num_words=50, input=seed_text, temp=0.8, mode='sto')\n",
        "for i, result in enumerate(beam_sto[:3]):  # Show top 3 results\n",
        "    print(f\"Candidate {i+1}: {decode(result)}\")\n",
        "\n",
        "print(\"\\n=== BEAM SEARCH ESTOCÁSTICO (Temperature = 1.2) ===\")\n",
        "beam_sto_high = beam_search(model, num_beams=5, num_words=50, input=seed_text, temp=1.2, mode='sto')\n",
        "for i, result in enumerate(beam_sto_high[:3]):  # Show top 3 results\n",
        "    print(f\"Candidate {i+1}: {decode(result)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "715a70c6"
      },
      "source": [
        "## Análisis del efecto de la temperatura\n",
        "\n",
        "La temperatura controla la \"creatividad\" del modelo:\n",
        "- **Temperatura baja (0.5)**: Más conservador, selecciona opciones más probables\n",
        "- **Temperatura media (1.0)**: Equilibrio entre coherencia y diversidad  \n",
        "- **Temperatura alta (1.5)**: Más creativo pero potencialmente menos coherente"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}